{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \ntrain_data = pd.read_csv('../input/sartorius-cell-instance-segmentation/train.csv')\nsamplesub = pd.read_csv('../input/sartorius-cell-instance-segmentation/sample_submission.csv')\ntrain_data.info()","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig, ax = plt.subplots(1,1)\ntrain_data.cell_type.value_counts().plot.bar()\nax.set_ylabel('Number of istances')\nax.set_xlabel('Cell types',rotation=0)\nfig.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tqdm\nimport os\nfrom termcolor import colored\n\nclass config:\n    dir = \"../input/sartorius-cell-instance-segmentation\"\n    train_path = dir + '/train'\n    test_path = dir +'/test'\n\ndef getImagePath(path):\n    image_names = []\n    for dirn, _, fnames in os.walk(path):\n        for fname in fnames:\n            fullpath = os.path.join(dirn, fname)\n            image_names.append(fullpath)\n    return image_names\n\ntrain_im_path = getImagePath(config.train_path)\ntest_im_path = getImagePath(config.test_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\ndef im_show(im_paths, r, c):\n    fig, ax = plt.subplots(nrows = r, ncols = c, \n                          figsize = (16,8))\n    for p, im_path in enumerate(im_paths):\n        im = cv2.imread(im_path)\n        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n        try: \n            ax.ravel()[p].imshow(im)     # ravel changes a 2-dimensional array or a multi-dimensional array into a contiguous flattened array\n            ax.ravel()[p].set_axis_off()\n        except:\n            continue;\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\ndef make_mask(mask_files, image_shape=(520, 704), color=False):\n    mask = np.zeros(image_shape).ravel()\n    for i, mask_file in enumerate(mask_files):\n        couples = np.array(mask_file.split()).reshape(-1, 2).astype(int)\n        couples[:, 1] = couples[:, 0] + couples[:, 1]\n        for couple in couples:\n            if color:\n                mask[couple[0]: couple[1]] = i\n            else:\n                mask[couple[0]: couple[1]] = 1\n    mask = mask.reshape(520, 704)\n    return mask\n\ndef plot_image(image_id='0030fd0e6378'):\n    fig, ax = plt.subplots(1, 2, figsize=(14,5))\n    cell_type = df_train.loc[df_train['id'] == image_id, 'cell_type'][0:1].values\n    \n    file_name = os.path.join(\n        '../input/sartorius-cell-instance-segmentation',\n        'train', image_id + '.png')\n    image = plt.imread(file_name)\n    mask_files = df_train.loc[df_train['id'] == image_id, 'annotation']\n    mask = make_mask(mask_files)\n\n    ax[0].imshow(\n        image,\n        cmap = plt.get_cmap('winter'), \n        origin = 'upper',\n        vmax = np.quantile(image, 0.99),\n        vmin = np.quantile(image, 0.05)\n    )\n    ax[0].set_title(f'Source [{image_id}]')\n    ax[0].axis('off')\n    \n    ax[1].imshow(\n        image,\n        cmap = plt.get_cmap('winter'), \n        origin = 'upper',\n        vmax = 255,\n        vmin = 0)\n    ax[1].imshow(mask, alpha=1, cmap=plt.get_cmap('seismic'))\n    ax[1].set_title(f'Source [{image_id}] + Mask {cell_type}')\n    ax[1].axis('off')\n    plt.show()\n\ndf_train = T1\n\nselect_image_ids = []\nselect_image_ids.append(df_train.loc[df_train['cell_type'] == 'astro', 'id'].sample(1).to_list()[0])\nselect_image_ids.append(df_train.loc[df_train['cell_type'] == 'cort', 'id'].sample(1).to_list()[0])\nselect_image_ids.append(df_train.loc[df_train['cell_type'] == 'shsy5y', 'id'].sample(1).to_list()[0])\n\nfor image_id in select_image_ids:\n    plot_image(image_id)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im_ht, im_width, im_channels = 520, 704, 1\n\ntrain_ids = train_data['id'].unique().tolist()\ntest_ids = samplesub['id'].unique().tolist()\n# print(test_ids)\n# print(train_ids)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = np.zeros((train_data['id'].nunique(),im_ht, im_width, im_channels), dtype = np.uint8)\ny_train = np.zeros((train_data['id'].nunique(),im_ht, im_width, im_channels), dtype = np.uint8)\nx_test = np.zeros((samplesub['id'].nunique(),im_ht, im_width, im_channels), dtype = np.uint8)\n\nfrom tqdm import tqdm\n\nTRAIN_PATH = '../input/sartorius-cell-instance-segmentation/train/'\n# https://www.kaggle.com/c/sartorius-cell-instance-segmentation/discussion/291627\ndef rle_decode(mask_rle, shape=(520, 704, 1)):\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)  # Needed to align to RLE direction\n\ndef rle_encode(img):\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\nfor n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n    path = TRAIN_PATH + id_\n    img = cv2.imread(path + '.png')[:,:]\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY).astype(np.float32) -125\n    img = np.expand_dims(img, axis = 2)\n    x_train[n] = img\n    \n    labels = train_data[train_data[\"id\"]\n                        == id_][\"annotation\"].tolist()\n    mask = np.zeros((520, 704, 1))\n    for label in labels:\n        mask += rle_decode(label, shape=(520, 704, 1))\n    mask = mask.clip(0, 1)\n    y_train[n] = mask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resize_img = np.zeros((train_data['id'].nunique(),512, 512,im_channels), dtype = np.uint8)\nresize_mask = np.zeros((train_data['id'].nunique(),512, 512,im_channels), dtype = np.uint8)\nfor i in range(len(x_train)):\n    img1 = x_train[i]\n    mask1 = y_train[i]\n    resized_img1 = cv2.resize(img1,(512,512),interpolation = cv2.INTER_AREA)\n    resized_img1 = np.expand_dims(resized_img1, axis = 2)\n   # print(resized_img1.shape)\n    resized_mask1 = cv2.resize(mask1,(512,512),interpolation = cv2.INTER_AREA)\n    resized_mask1 = np.expand_dims(resized_mask1, axis = 2)\n    #print(resized_mask1.shape)\n    resize_img[i] = resized_img1\n    resize_mask[i] = resized_mask1\n    print(resize_mask.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = resize_img\ny_train = resize_mask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get and resize test images\ntest_images_id = []\nX_test = np.zeros((samplesub['id'].nunique(), im_ht, im_width, im_channels), dtype=np.uint8)\nfor n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n    path = TRAIN_PATH.replace('train', 'test') + id_\n    img = cv2.imread(path + '.png')[:,:]\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY).astype(np.float32) -125\n    img = np.expand_dims(img, axis = 2)\n    print(img.shape)\n    X_test[n] = img\n    test_images_id.append(id_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(X_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resize_test = np.zeros((samplesub['id'].nunique(),512, 512,im_channels), dtype = np.uint8)\n\nfor i in range(len(X_test)):\n    img1 = X_test[i]\n    #print(img1.shape)\n    resized_test1 = cv2.resize(img1,(512,512),interpolation = cv2.INTER_AREA)\n    resized_test1 = np.expand_dims(resized_test1, axis = 2)\n    #print(resized_test1.shape)\n    resize_test[i] = resized_test1\n\nX_test = resize_test\nprint(X_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport os\nimport skimage.io as io\nimport skimage.transform as trans\nimport numpy as np\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\n# from keras import backend as keras\n\nimport keras\n# from keras.models import Model,load_model\n# # from keras import layers\nfrom tensorflow.keras.losses import BinaryCrossentropy\n\ndef unet(pretrained_weights = None,input_size = (512,512,1)):\n    inputs = Input(input_size)\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n    drop4 = Dropout(0.5)(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n\n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n    drop5 = Dropout(0.5)(conv5)\n\n    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n    merge6 = concatenate([drop4,up6], axis = 3)\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n\n    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n    merge7 = concatenate([conv3,up7], axis = 3)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n\n    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n    merge8 = concatenate([conv2,up8], axis = 3)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n\n    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n    merge9 = concatenate([conv1,up9], axis = 3)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n\n    model = Model(inputs = inputs, outputs = conv10)\n\n#     model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n    model.compile(optimizer = 'adam', loss = BinaryCrossentropy(),metrics = ['accuracy'])\n#     model.summary()\n\n    if(pretrained_weights):\n    \tmodel.load_weights(pretrained_weights)\n\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = unet()\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping\n# Save the best models and its weights at every step \n\nmodel_output = os.path.join('./','model.h5')\nmodel_checkpoint = keras.callbacks.ModelCheckpoint(\n    model_output,save_best_only = True, save_weights_only = True)\n\n# Reduces the learning rate for no model improvement\nlr_reduce = keras.callbacks.ReduceLROnPlateau( monitor='val_loss', factor=0.1, patience=10, verbose=0,\n    mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n\nes =  EarlyStopping(patience = 10, verbose = 1)\n\nhist = model.fit(x_train, y_train, batch_size = 5,validation_steps=0.5,epochs = 60,callbacks = [EarlyStopping(), model_checkpoint, lr_reduce])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%checking\nprint(x_train.shape, y_train.shape)\nprint(x_train[0:5].shape)\npred = model.predict(x_train[0:5])\n#print(pred.shape)\ntrain_preds = (pred > 0.5).astype(np.uint8)\nplt.imshow(train_preds[0],cmap = 'gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot model loss\nloss = hist.history['loss']\nplt.figure()\nplt.plot(hist.epoch, loss, 'r', label='Training loss')\nplt.title('model loss')\nplt.xlabel('epochs')\nplt.ylabel('Loss')\nplt.legend(['loss'],loc = 'right')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# testing\npreds_test = model.predict(X_test, verbose=1)\npreds_test_t = (preds_test >= 0.5).astype(np.uint8)\n# Test samples\nfrom random import randint\nix = randint(0, len(preds_test_t)-1)\nprint(ix)\nplt.imshow(X_test[ix])\nplt.show()\nplt.imshow(np.squeeze(preds_test_t[ix]))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}